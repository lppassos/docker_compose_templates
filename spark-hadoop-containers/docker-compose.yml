# Description of the docker environment for testing spark jobs
#
# Instances a very small cluster with a master node and a worker node
#
version: "2"

services:
  namenode:
    image: apache/hadoop:3
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./configs/config
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
      HADOOP_HOME: "/opt/hadoop"
    volumes:
      - namenodedata:/data

  datanode:
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./configs/config
    volumes:
      - datanodedata:/data
    depends_on:
      - namenode

  resourcemanager:
    image: apache/hadoop:3
    command: ["yarn", "resourcemanager"]
    ports:
      - 8088:8088
    env_file:
      - ./configs/config

  nodemanager:
    image: apache/hadoop:3
    command: ["yarn", "nodemanager"]
    ports:
      - 8042:8042
    env_file:
      - ./configs/config

  # This is a temporary container to install the tez library in hdfs
  tez_installer:
    image: apache/hive:4.0.0
    entrypoint: ["bash", "/install_tez.sh"]
    environment:
      HADOOP_CONF_DIR: /hive_conf
    volumes:
      - ./configs:/hive_conf
      - ./install_tez.sh:/install_tez.sh
    depends_on:
      - datanode

  # HIVE server to more easily query the data from hadoop
  hive_server:
    image: apache/hive:4.0.0
    ports:
      - 10000:10000
      - 10002:10002
    environment:
      SERVICE_NAME: "hiveserver2"
      HIVE_CUSTOM_CONF_DIR: "/hive_conf"
      IS_RESUME: "true"
    volumes:
      - ./configs:/hive_conf
      - hiveserverdata:/opt/hive/data/warehouse
    depends_on:
      database:
        condition: service_healthy
      hivemetastore:
        condition: service_started

  # Expose the hive metastore instead of keeping it embedded in hiveserver
  hivemetastore:
    image: apache/hive:4.0.0
    ports:
      - 9083:9083
    environment:
      - SERVICE_NAME=metastore
      - HIVE_CUSTOM_CONF_DIR=/hive_conf
      - DB_DRIVER=mysql
    volumes:
      - ./configs:/hive_conf
      - hiveserverdata:/opt/hive/data/warehouse
      - ./lib/mysql-connector-java-5.1.49.jar:/opt/hive/lib/mysql-connector-java-5.1.49.jar
    depends_on:
      database:
        condition: service_healthy

  # Front-end to be able to query hive more easily
  hue_server:
    image: gethue/hue:latest
    ports:
      - 8888:8888
    volumes:
      - ./configs/hue/hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    depends_on:
      database:
        condition: service_healthy

  # MYSQL Database to support hue
  database:
    image: mysql:5.7
    ports:
      - 33061:3306
    command: --init-file /data/application/init.sql
    volumes:
      - mysqldata:/var/lib/mysql
      - ./configs/mysql/init.sql:/data/application/init.sql
    environment:
      MYSQL_ROOT_USER: root
      MYSQL_ROOT_PASSWORD: secret
      MYSQL_DATABASE: hue
      MYSQL_USER: adm
      MYSQL_PASSWORD: secret
    healthcheck:
      test: mysqladmin ping --user=adm --password=secret

  # Spark client
  spark:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - YARN_CONF_DIR=/opt/bitnami/spark/custom_configs
    ports:
      - "8080:8080"
    volumes:
      - ./configs/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./configs:/opt/bitnami/spark/custom_configs
      - .:/opt/bitnami/spark/scripts

volumes:
  mysqldata:
  hiveserverdata:
  namenodedata:
  datanodedata:

networks:
  default:
    name: hadoop
